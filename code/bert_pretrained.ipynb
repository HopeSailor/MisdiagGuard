{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9836a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ssl\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bbe26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['SSL_CERT_FILE'] = ssl.get_default_verify_paths().openssl_cafile\n",
    "# Read data to DataFrame\n",
    "df = pd.read_csv('G:/labeled_misdiagnosis.csv')\n",
    "train_validation = df[['主诉内容', 'Misdiag']]\n",
    "test_data1 = pd.read_csv('./code/data/pretrained/train.txt', sep='\\t')\n",
    "test_data2 = pd.read_csv('./code/data/pretrained/test.txt', sep='\\t')\n",
    "test = pd.concat([test_data1, test_data2], ignore_index=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, validation = train_test_split(train_validation, test_size=0.20, random_state=42)\n",
    "# Rename columns in training set\n",
    "train = train.rename(columns={'主诉内容': 'text'})\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "train['Misdiag'] = train['Misdiag'].astype(int)\n",
    "# Rename columns in validation set\n",
    "validation = validation.rename(columns={'主诉内容': 'text'})\n",
    "validation.reset_index(inplace=True, drop=True)\n",
    "validation['Misdiag'] = validation['Misdiag'].astype(int)\n",
    "# Rename columns in test set\n",
    "test = test.rename(columns={'Complain': 'text'})\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "test['Misdiag'] = test['Misdiag'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3ccd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        text = row['text']\n",
    "        label = row['Misdiag']\n",
    "        inputs = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        inputs = {key: value.squeeze(0) for key, value in inputs.items()}  # Remove the batch dimension\n",
    "        inputs['labels'] = torch.tensor(label)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525940c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = './code/bert_pretrained'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d090ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train, tokenizer)\n",
    "validation_dataset = CustomDataset(validation, tokenizer)\n",
    "test_dataset = CustomDataset(test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7532aeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_keys = batch[0].keys()\n",
    "    outputs = {key: torch.stack([item[key] for item in batch]) for key in input_keys}\n",
    "    return outputs\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./code/bert_pretrained1/results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=1e-4,  # Here is where you define the learning rate\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_dir='./code/bert_pretrained1/logs',\n",
    ")\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, true_labels = eval_pred.predictions, eval_pred.label_ids\n",
    "\n",
    "    # convert logits to probabilities\n",
    "    probabilities = torch.nn.functional.softmax(torch.from_numpy(predictions), dim=-1).numpy()\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, np.argmax(predictions, axis=-1))\n",
    "    precision = precision_score(true_labels, np.argmax(predictions, axis=-1), average='weighted', zero_division=1)\n",
    "    recall = recall_score(true_labels, np.argmax(predictions, axis=-1), average='weighted')\n",
    "    f1 = f1_score(true_labels, np.argmax(predictions, axis=-1), average='weighted')\n",
    "\n",
    "    auroc = roc_auc_score(true_labels, probabilities[:, 1])\n",
    "    auprc = average_precision_score(true_labels, probabilities[:, 1], average='weighted')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auroc': auroc,\n",
    "        'auprc': auprc,\n",
    "    }\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()\n",
    "test_results = trainer.predict(test_dataset)\n",
    "test_metrics = compute_metrics(test_results)\n",
    "print(\"Test Set Metrics:\")\n",
    "for key, value in test_metrics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f7a4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec88258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to hold DataFrames\n",
    "dfs = []\n",
    "for root_dir, sub_dir, files in os.walk(r'G:/emr'):\n",
    "    for file in tqdm(files, desc = 'Excel import', ncols = 100): # Wrap your iterable with tqdm()\n",
    "        df = pd.read_excel(os.path.join(root_dir, file))\n",
    "        dfs.append(df)\n",
    "        gc.collect()  # Explicitly free memory\n",
    "# Concatenate all DataFrames at once\n",
    "result_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e264b8be",
   "metadata": {},
   "source": [
    "# Statistical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc105a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat(dfs, ignore_index=True)\n",
    "# Observations\n",
    "print(len(result_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb5f3f6",
   "metadata": {},
   "source": [
    "## Find the same patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905b526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new columns for Name, Gender, and Age\n",
    "result_df['Name'] = None\n",
    "result_df['Gender'] = None\n",
    "result_df['Age'] = None\n",
    "result_df.reset_index(inplace=True, drop=True)\n",
    "# Fill the new columns with values from XmlValue based on the content of XmlField\n",
    "for idx, row in result_df.iterrows():\n",
    "    if '姓名' in row['XmlField']:\n",
    "        result_df.loc[idx, 'Name'] = row['XmlValue']\n",
    "    elif '性别' in row['XmlField']:\n",
    "        result_df.loc[idx, 'Gender'] = row['XmlValue']\n",
    "    elif '年龄' in row['XmlField']:\n",
    "        result_df.loc[idx, 'Age'] = row['XmlValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8498a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['Name', 'Gender', 'Age']:\n",
    "    result_df[column] = result_df.groupby('HospId')[column].transform('first')\n",
    "# Initialize a new column for patient IDs\n",
    "result_df['PatientID'] = -1\n",
    "# Find the same patient using name, gender, and age\n",
    "patient_cohort = result_df\n",
    "unique_patients = patient_cohort.drop_duplicates(subset=['Name', 'Gender', 'Age'])\n",
    "patient_ids = range(len(unique_patients))\n",
    "    \n",
    "patient_id_dict = {\n",
    "    (row.Name, row.Gender, row.Age): id \n",
    "    for row, id in zip(unique_patients.itertuples(), patient_ids)\n",
    "}\n",
    "for row in result_df.itertuples():\n",
    "    patient_info = (row.Name, row.Gender, row.Age)\n",
    "    if patient_info in patient_id_dict:\n",
    "        result_df.at[row.Index, 'PatientID'] = patient_id_dict[patient_info]\n",
    "# Patient count\n",
    "print(result_df['PatientID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4ffc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age convert\n",
    "import re\n",
    "\n",
    "def convert_age_to_years(age_str):\n",
    "    # Check if input is not string\n",
    "    if not isinstance(age_str, str):\n",
    "        return age_str\n",
    "\n",
    "    # Pattern for years, months, and days\n",
    "    years_pattern = r'(\\d+)\\s*岁'\n",
    "    months_pattern = r'(\\d+)\\s*个月'\n",
    "    days_pattern = r'(\\d+)\\s*天'\n",
    "\n",
    "    # Search for matches\n",
    "    years_match = re.search(years_pattern, age_str)\n",
    "    months_match = re.search(months_pattern, age_str)\n",
    "    days_match = re.search(days_pattern, age_str)\n",
    "\n",
    "    # Extract matched numbers and convert to float\n",
    "    years = float(years_match.group(1)) if years_match else 0\n",
    "    months = float(months_match.group(1)) / 12 if months_match else 0\n",
    "    days = float(days_match.group(1)) / 365.25 if days_match else 0\n",
    "\n",
    "    # Return sum of all (converted to years)\n",
    "    return years + months + days\n",
    "\n",
    "# Apply the function to the 'Age' column\n",
    "result_df['Age'] = result_df['Age'].apply(convert_age_to_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8460b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_gender_name = result_df[['Name', 'Gender', 'Age', 'PatientID']]\n",
    "age_gender_name = age_gender_name.drop_duplicates()\n",
    "age_gender_name.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925a0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender\n",
    "print(age_gender_name['Gender'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcd5773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age\n",
    "print(age_gender_name.Age.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bcf3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age and gender statistics\n",
    "male_EHR = age_gender_name.loc[age_gender_name['Gender'] == '男']\n",
    "female_EHR = age_gender_name.loc[age_gender_name['Gender'] == '女']\n",
    "male_infants_and_toddlers = male_EHR.loc[(2 >= male_EHR['Age']) & (male_EHR['Age'] > 0)]\n",
    "female_infants_and_toddlers = female_EHR.loc[(2 >= female_EHR['Age']) & (female_EHR['Age'] > 0)]\n",
    "male_preschool = male_EHR.loc[(4 >= male_EHR['Age']) & (male_EHR['Age'] > 2)]\n",
    "female_preschool = female_EHR.loc[(4 >= female_EHR['Age']) & (female_EHR['Age'] > 2)]\n",
    "male_school_age_children = male_EHR.loc[(12 >= male_EHR['Age']) & (male_EHR['Age'] > 4)]\n",
    "female_school_age_children = female_EHR.loc[(12 >= female_EHR['Age']) & (female_EHR['Age'] > 4)]\n",
    "male_teenagers = male_EHR.loc[(19 >= male_EHR['Age']) & (male_EHR['Age'] > 12)]\n",
    "female_teenagers = female_EHR.loc[(19 >= female_EHR['Age']) & (female_EHR['Age'] > 12)]\n",
    "male_young_adults = male_EHR.loc[(34 >= male_EHR['Age']) & (male_EHR['Age'] > 19)]\n",
    "female_young_adults = female_EHR.loc[(34 >= female_EHR['Age']) & (female_EHR['Age'] > 29)]\n",
    "male_adults = male_EHR.loc[(49 >= male_EHR['Age']) & (male_EHR['Age'] > 34)]\n",
    "female_adults = female_EHR.loc[(49 >= female_EHR['Age']) & (female_EHR['Age'] > 34)]\n",
    "male_middle_aged_adults = male_EHR.loc[(64 >= male_EHR['Age']) & (male_EHR['Age'] > 49)]\n",
    "female_middle_aged_adults = female_EHR.loc[(64 >= female_EHR['Age']) & (female_EHR['Age'] > 49)]\n",
    "male_seniors = male_EHR.loc[male_EHR['Age'] > 64]\n",
    "female_seniors = female_EHR.loc[female_EHR['Age'] > 64]\n",
    "print('The ratio of each age and gender groups are:\\n' +\n",
    "      'Male: \\n'+\n",
    "      'male_infants_and_toddlers: ' + str(len(male_infants_and_toddlers)/len(age_gender_name)) + '\\n' +\n",
    "      'male_preschool: ' + str(len(male_preschool)/len(age_gender_name))+'\\n' +\n",
    "      'male_school_age_children: ' + str(len(male_school_age_children)/len(age_gender_name))+'\\n'+\n",
    "      'male_teenagers: '+ str(len(male_teenagers)/len(age_gender_name))+'\\n'+\n",
    "      'male_young_adults: '+ str(len(male_young_adults)/len(age_gender_name))+'\\n'+\n",
    "      'male_adults: '+ str(len(male_adults)/len(age_gender_name))+'\\n'+\n",
    "      'male_middle_aged_adults: '+ str(len(male_middle_aged_adults)/len(age_gender_name))+'\\n'+\n",
    "      'male_seniors'+ str(len(male_seniors)/len(age_gender_name))+'\\n'+\n",
    "      'Female: \\n'+\n",
    "      'female_infants_and_toddlers: ' + str(len(female_infants_and_toddlers) / len(age_gender_name)) + '\\n' +\n",
    "      'female_preschool: ' + str(len(female_preschool) / len(age_gender_name)) + '\\n' +\n",
    "      'female_school_age_children: ' + str(len(female_school_age_children) / len(age_gender_name)) + '\\n' +\n",
    "      'female_teenagers: ' + str(len(female_teenagers) / len(age_gender_name)) + '\\n' +\n",
    "      'female_young_adults: ' + str(len(female_young_adults) / len(age_gender_name)) + '\\n' +\n",
    "      'female_adults: ' + str(len(female_adults) / len(age_gender_name)) + '\\n' +\n",
    "      'female_middle_aged_adults: ' + str(len(female_middle_aged_adults) / len(age_gender_name)) + '\\n' +\n",
    "      'female_seniors' + str(len(female_seniors) / len(age_gender_name)) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e270d567",
   "metadata": {},
   "source": [
    "## Search for misdiagnosis using empirical triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad01bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the pivot operation\n",
    "pivot_df = pd.pivot_table(result_df, index=['PatientID', 'Name', 'Gender', 'Age', 'OperTime', 'InEmrId'], columns='XmlField', values='XmlValue', aggfunc='first')\n",
    "pivot_df['PatientID'] = pivot_df.index.get_level_values('PatientID')\n",
    "pivot_df['Name'] = pivot_df.index.get_level_values('Name')\n",
    "pivot_df['Gender'] = pivot_df.index.get_level_values('Gender')\n",
    "pivot_df['Age'] = pivot_df.index.get_level_values('Age')\n",
    "pivot_df['OperTime'] = pd.to_datetime(pivot_df.index.get_level_values('OperTime'))\n",
    "pivot_df['InEmrId'] = pivot_df.index.get_level_values('InEmrId')\n",
    "pivot_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044be3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def misdiagnosis_label(df):\n",
    "    df = df.sort_values(by=['PatientID', 'OperTime'])  # Sort the DataFrame by 'PatientID' and 'OperTime'\n",
    "    df['TimeDiff'] = df.groupby('PatientID')['OperTime'].diff()  # Calculate time difference between consecutive readmissions\n",
    "    df['Misdiag'] = ((df['TimeDiff'] >= pd.Timedelta(days=1)) & (df['TimeDiff'] <= pd.Timedelta(days=14))).astype(int)\n",
    "    df['Misdiag'] = df['Misdiag'].shift(-1)\n",
    "    df.at[df.index[-1], 'Misdiag'] = 0\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "labeled_misdiagnosis = misdiagnosis_label(pivot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac514ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name_chinese = pd.read_excel('G:/column_name_chinese.xlsx')\n",
    "for col in labeled_misdiagnosis.columns:\n",
    "    if col in column_name_chinese['字段名'].values:\n",
    "        # get the English name corresponding to the Chinese name\n",
    "        english_name = column_name_chinese.loc[column_name_chinese['字段名'] == col, '字段含义'].values[0]\n",
    "        labeled_misdiagnosis.rename(columns={col: english_name}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute proportion of null values in each column\n",
    "null_proportion = labeled_misdiagnosis.isnull().mean()\n",
    "# Get columns to keep\n",
    "cols_to_keep = null_proportion[null_proportion <= 0.8].index\n",
    "# Keep only the columns in cols_to_keep and drop the rest\n",
    "labeled_misdiagnosis = labeled_misdiagnosis[cols_to_keep]\n",
    "df_not_null = labeled_misdiagnosis[labeled_misdiagnosis['主诉内容'].notna()]\n",
    "file_path = 'G:/labeled_misdiagnosis.csv'  # Path to save the CSV file\n",
    "df_not_null.to_csv(file_path,sep=',',index=True,header=True, encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da01d2f4",
   "metadata": {},
   "source": [
    "## Plot correlation of patient readmission and diagnostic errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c1bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95418768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TimeDiff to days\n",
    "labeled_misdiagnosis['TimeDiff_days'] = labeled_misdiagnosis['TimeDiff'].dt.days\n",
    "\n",
    "# Calculate misdiagnosis rate\n",
    "labeled_misdiagnosis['Misdiag_rate'] = labeled_misdiagnosis.groupby('PatientID')['Misdiag'].transform('mean') * 100\n",
    "\n",
    "# Define misdiagnosis rate bins\n",
    "misdiag_rate_bins = np.linspace(0, 100, 11) # 0-100% in 5% increments\n",
    "\n",
    "# Add a column to count readmissions per patient\n",
    "labeled_misdiagnosis['Readmission_Count'] = labeled_misdiagnosis[labeled_misdiagnosis['TimeDiff_days']>0].groupby('PatientID')['TimeDiff_days'].transform('count')\n",
    "# Define readmission count bins (you can modify this according to your data distribution)\n",
    "readmission_count_bins = np.linspace(0, labeled_misdiagnosis['Readmission_Count'].max(), 21)\n",
    "\n",
    "# Create a DataFrame with misdiagnosis rate, readmission count, and patient count for each bin\n",
    "misdiag_subgroups = pd.DataFrame()\n",
    "misdiag_subgroups['Misdiag_rate'] = pd.cut(labeled_misdiagnosis['Misdiag_rate'], bins=misdiag_rate_bins)\n",
    "misdiag_subgroups['Readmission_Count'] = pd.cut(labeled_misdiagnosis['Readmission_Count'], bins=readmission_count_bins)\n",
    "misdiag_subgroups['Patient_Count'] = labeled_misdiagnosis.groupby(['Misdiag_rate', 'Readmission_Count'])['PatientID'].transform('count')\n",
    "\n",
    "# Remove duplicate rows (since each patient will have the same values for all three columns)\n",
    "misdiag_subgroups.drop_duplicates(inplace=True)\n",
    "\n",
    "# Find mean of 'Patient_Count' for each combination of 'Misdiag_rate' and 'Readmission_Count'\n",
    "misdiag_subgroups = misdiag_subgroups.groupby(['Misdiag_rate', 'Readmission_Count'])['Patient_Count'].mean().reset_index()\n",
    "\n",
    "# Pivot the data for the heatmap\n",
    "pivot = misdiag_subgroups.pivot(index='Readmission_Count', columns='Misdiag_rate', values='Patient_Count')\n",
    "\n",
    "# Generate the heatmap\n",
    "fig, ax = plt.subplots(figsize=(5, 8))\n",
    "cax = sns.heatmap(pivot, cmap=\"OrRd\", linewidths=0.25, linecolor='black') # Add a gray border to each cell\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.axis('off')\n",
    "# Add a black border line to the heatmap\n",
    "for _, spine in ax.spines.items():\n",
    "    spine.set_visible(True)\n",
    "    spine.set_color('black')\n",
    "    spine.set_linewidth(0.25)\n",
    "\n",
    "ax.invert_yaxis() # Make y-axis start at 0\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('./heatmap_count.png', dpi=1200)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddccc217",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add a column to calculate the mean interval between readmissions per patient\n",
    "labeled_misdiagnosis['Mean_Readmission_Interval'] = labeled_misdiagnosis[labeled_misdiagnosis['TimeDiff_days']>0].groupby('PatientID')['TimeDiff_days'].transform('mean')\n",
    "# Define mean readmission interval bins (you can modify this according to your data distribution)\n",
    "readmission_interval_bins = np.linspace(0, labeled_misdiagnosis['Mean_Readmission_Interval'].max(), 21)\n",
    "\n",
    "\n",
    "\n",
    "# Create a DataFrame with misdiagnosis rate, readmission count, and patient count for each bin\n",
    "misdiag_subgroups = pd.DataFrame()\n",
    "misdiag_subgroups['Misdiag_rate'] = pd.cut(labeled_misdiagnosis['Misdiag_rate'], bins=misdiag_rate_bins)\n",
    "misdiag_subgroups['Mean_Readmission_Interval'] = pd.cut(labeled_misdiagnosis['Mean_Readmission_Interval'], bins=readmission_interval_bins)\n",
    "misdiag_subgroups['Patient_Count'] = labeled_misdiagnosis.groupby(['Misdiag_rate', 'Mean_Readmission_Interval'])['PatientID'].transform('count')\n",
    "\n",
    "# Remove duplicate rows (since each patient will have the same values for all three columns)\n",
    "misdiag_subgroups.drop_duplicates(inplace=True)\n",
    "\n",
    "# Find mean of 'Patient_Count' for each combination of 'Misdiag_rate' and 'Readmission_Count'\n",
    "misdiag_subgroups = misdiag_subgroups.groupby(['Misdiag_rate', 'Mean_Readmission_Interval'])['Patient_Count'].mean().reset_index()\n",
    "\n",
    "# Pivot the data for the heatmap\n",
    "pivot = misdiag_subgroups.pivot(index='Mean_Readmission_Interval', columns='Misdiag_rate', values='Patient_Count')\n",
    "\n",
    "# Generate the heatmap\n",
    "fig, ax = plt.subplots(figsize=(5, 8))\n",
    "cax = sns.heatmap(pivot, cmap=\"YlGnBu\", linewidths=0.25, linecolor='black') # Add a gray border to each cell\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.axis('off')\n",
    "# Add a black border line to the heatmap\n",
    "for _, spine in ax.spines.items():\n",
    "    spine.set_visible(True)\n",
    "    spine.set_color('black')\n",
    "    spine.set_linewidth(0.25)\n",
    "\n",
    "ax.invert_yaxis() # Make y-axis start at 0\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('./heatmap_interval.png', dpi=1200)\n",
    "plt.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beef6211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of patients per department and calculate proportions\n",
    "department_counts = pivot_df['科室'].value_counts(normalize=True)\n",
    "\n",
    "# Count the number of patients per ethnicity and calculate proportions\n",
    "ethnicity_counts = pivot_df['民族'].value_counts(normalize=True)\n",
    "\n",
    "import openpyxl\n",
    "#with pd.ExcelWriter('G:/deparment_ethnicity.xlsx') as writer:  \n",
    "    #department_counts.to_excel(writer, sheet_name='Department Counts')\n",
    "    #ethnicity_counts.to_excel(writer, sheet_name='Ethnicity Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743f748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misdiagnosis ratio in derivation cohort\n",
    "misdiag_percentage = (df_not_null['Misdiag'] == 1).mean() * 100\n",
    "print(misdiag_percentage)\n",
    "# EMRs in derivation cohort\n",
    "len(labeled_misdiagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10759916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_not_null.copy()\n",
    "\n",
    "# Create a new DataFrame instead of a slice\n",
    "selected_df = df_copy[['主诉内容', '传染病史', '其他病史', '心血管病史', '手术外伤史', '过敏史', '预防接种史', 'Misdiag']].copy()\n",
    "\n",
    "# Fill NaNs in all involved columns\n",
    "for col in ['主诉内容', '传染病史', '其他病史', '心血管病史', '手术外伤史', '过敏史', '预防接种史']:\n",
    "    selected_df.loc[:, col] = selected_df.loc[:, col].fillna('')\n",
    "\n",
    "# Combine the text columns\n",
    "selected_df.loc[:, 'combined_text'] = selected_df['主诉内容'] + ' ' + selected_df['传染病史'] + ' ' + selected_df['其他病史'] + ' ' + selected_df['心血管病史'] + ' ' + selected_df['手术外伤史'] + ' ' + selected_df['过敏史'] + ' ' + selected_df['预防接种史']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe737f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select only the 'combined_text' and 'Misdiag' columns\n",
    "export_df = selected_df[['combined_text', 'Misdiag']]\n",
    "\n",
    "# Export the DataFrame to a .txt file\n",
    "export_df.to_csv('selected_df.txt', index=False, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

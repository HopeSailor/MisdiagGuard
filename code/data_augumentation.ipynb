{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0948346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ssl\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments, MarianMTModel, MarianTokenizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, roc_curve, auc, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25630170",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['SSL_CERT_FILE'] = ssl.get_default_verify_paths().openssl_cafile\n",
    "# Read data to DataFrame\n",
    "df = pd.read_csv('G:/labeled_misdiagnosis.csv')\n",
    "train_validation = df[['主诉内容', 'Misdiag']]\n",
    "test_data1 = pd.read_csv('./data/pretrained/train.txt', sep='\\t')\n",
    "test_data2 = pd.read_csv('./data/pretrained/test.txt', sep='\\t')\n",
    "test = pd.concat([test_data1, test_data2], ignore_index=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, validation = train_test_split(train_validation, test_size=0.20, random_state=42)\n",
    "# Rename columns in training set\n",
    "train = train.rename(columns={'主诉内容': 'text'})\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "train['Misdiag'] = train['Misdiag'].astype(int)\n",
    "# Rename columns in validation set\n",
    "validation = validation.rename(columns={'主诉内容': 'text'})\n",
    "validation.reset_index(inplace=True, drop=True)\n",
    "validation['Misdiag'] = validation['Misdiag'].astype(int)\n",
    "# Rename columns in test set\n",
    "test = test.rename(columns={'Complain': 'text'})\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "test['Misdiag'] = test['Misdiag'].astype(int)\n",
    "misdiag_data = train[train['Misdiag'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e4cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model used for translate Chinese to English\n",
    "target_model_name = './data_augumentation/chinese_to_english'\n",
    "target_tokenizer_name = './data_augumentation/chinese_to_english'\n",
    "target_model = MarianMTModel.from_pretrained(target_model_name)\n",
    "target_tokenizer = MarianTokenizer.from_pretrained(target_tokenizer_name)\n",
    "\n",
    "# model used for translate English to Chinese\n",
    "output_model_name = './data_augumentation/english_to_chinese'\n",
    "output_tokenizer_name = './data_augumentation/english_to_chinese'\n",
    "output_model = MarianMTModel.from_pretrained(output_model_name)\n",
    "output_tokenizer = MarianTokenizer.from_pretrained(output_tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d0b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text, model, tokenizer, language=\"zh\"):\n",
    "    encoded = tokenizer(text, truncation=True, padding='longest', return_tensors=\"pt\")\n",
    "    # Generate translation using model\n",
    "    translated = model.generate(**encoded)\n",
    "    # Convert the generated tokens indices back into text\n",
    "    translated_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "def back_translate(texts, source_lang=\"en\", target_lang=\"fr\"):\n",
    "    # Translate from source to target language\n",
    "    en_texts = translate(texts, target_model, target_tokenizer, language=target_lang)\n",
    "    # Translate from target language back to source language\n",
    "    back_translated_texts = translate(en_texts, output_model, output_tokenizer, language=source_lang)\n",
    "    return back_translated_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280237cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_texts = misdiag_data['text'].tolist()\n",
    "# Perform back translation\n",
    "augumentated_texts = []\n",
    "for i in tqdm(range(len(chinese_texts)), ncols=100):\n",
    "    aug_text = back_translate(chinese_texts[i], source_lang=\"zh\", target_lang=\"en\")\n",
    "    augumentated_texts.append(aug_text)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ab381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in augumentated_texts for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be2dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame({\n",
    "    'text': flat_list,\n",
    "    'Misdiag': [1]*len(flat_list)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a77ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.append(new_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099617cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        text = row['text']\n",
    "        label = row['Misdiag']\n",
    "        inputs = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        inputs = {key: value.squeeze(0) for key, value in inputs.items()}  # Remove the batch dimension\n",
    "        inputs['labels'] = torch.tensor(label)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338a9101",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = './code/bert_pretrained3'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "train_dataset = CustomDataset(train, tokenizer)\n",
    "validation_dataset = CustomDataset(validation, tokenizer)\n",
    "test_dataset = CustomDataset(test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5920e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_keys = batch[0].keys()\n",
    "    outputs = {key: torch.stack([item[key] for item in batch]) for key in input_keys}\n",
    "    return outputs\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./code/bert_pretrained/results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=1e-4,  # Here is where you define the learning rate\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_dir='./code/bert_pretrained/logs',\n",
    ")\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, true_labels = eval_pred.predictions, eval_pred.label_ids\n",
    "\n",
    "    # convert logits to probabilities\n",
    "    probabilities = torch.nn.functional.softmax(torch.from_numpy(predictions), dim=-1).numpy()\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, np.argmax(predictions, axis=-1))\n",
    "    precision = precision_score(true_labels, np.argmax(predictions, axis=-1), average='weighted', zero_division=1)\n",
    "    recall = recall_score(true_labels, np.argmax(predictions, axis=-1), average='weighted')\n",
    "    f1 = f1_score(true_labels, np.argmax(predictions, axis=-1), average='weighted')\n",
    "\n",
    "    auroc = roc_auc_score(true_labels, probabilities[:, 1])\n",
    "    auprc = average_precision_score(true_labels, probabilities[:, 1], average='weighted')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auroc': auroc,\n",
    "        'auprc': auprc,\n",
    "    }\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()\n",
    "test_results = trainer.predict(test_dataset)\n",
    "test_metrics = compute_metrics(test_results)\n",
    "print(\"Test Set Metrics:\")\n",
    "for key, value in test_metrics.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5273033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = BertForSequenceClassification.from_pretrained('./code/bert_pretrained3/results/checkpoint-7500')\n",
    "# Predict probabilities\n",
    "predictions = trainer.predict(test_dataset)\n",
    "# Convert logits to probabilities\n",
    "probabilities = torch.nn.functional.softmax(torch.from_numpy(predictions.predictions), dim=-1).numpy()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(probabilities[:, 1], bins=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e02400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply threshold\n",
    "threshold = 0.5\n",
    "predicted_labels = (probabilities[:, 1] >= threshold).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(test['Misdiag'], predicted_labels)\n",
    "precision = precision_score(test['Misdiag'], predicted_labels, average='weighted', zero_division=1)\n",
    "recall = recall_score(test['Misdiag'], predicted_labels, average='weighted')\n",
    "f1 = f1_score(test['Misdiag'], predicted_labels, average='weighted')\n",
    "auroc = roc_auc_score(test['Misdiag'], probabilities[:, 1])\n",
    "auprc = average_precision_score(test['Misdiag'], probabilities[:, 1], average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"AUROC: {auroc}\")\n",
    "print(f\"AUPRC: {auprc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cce2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predicted_labels).to_csv('G:/bert_data_augumentation_free_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a0686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, _ = precision_recall_curve(test['Misdiag'], probabilities[:, 1])\n",
    "pr_auc = auc(recall, precision)\n",
    "pr_auc = auc(recall, precision)\n",
    "fpr, tpr, _ = roc_curve(test['Misdiag'], probabilities[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "lw = 2  # Line width\n",
    "\n",
    "# ROC curve\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')  # Random classifier\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Precision-Recall curve\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, color='blue', lw=lw, label='PR curve (area = %0.2f)' % pr_auc)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bdc155",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train).to_csv('G:/train.csv')\n",
    "pd.DataFrame(validation).to_csv('G:/validation.csv')\n",
    "pd.DataFrame(test).to_csv('G:/test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
